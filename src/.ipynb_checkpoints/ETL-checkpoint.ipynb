{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL\n",
    "\n",
    "La primera columna \"node\" contiene el nombre del nodo en el que se toman los datos (eg c7102). Para los datos de las enfriadoras, aparecen en esta columna como \"1\" y \"2\" (enfriadora 1, enfriadora 2 respectivamente) para los datos de temperatura y presión y como \"basement\" para los datos de consumo (la enfriadora 1 se corresponde con la columna \"Power13\" y la 2 con \"Power14\").\n",
    "\n",
    "La segunda y tercera columna incluyen los rangos de fecha para las series temporales de esa fila. Como se indicó antes, de 2018/01/01 hasta 2021/01/06.\n",
    "\n",
    "La columna 4 \"power\": incluye los consumos de los nodos (ie node=\"cxxxx\"). En cada celda se encuentra una serie temporal en formato diccionario en el que la key se corresponde con el timestamp del dato.\n",
    "\n",
    "Las columnas 5 y 6 'Power13', 'Power14' se corresponden con el consumo de las enfriadoras (medido en los cuadros PM13 PM14) como se indicó en la explicación de la columna nodo. Solo debería tener datos para node=\"basement\". En cada celda se encuentra una serie temporal en formato diccionario en el que la key se corresponde con el timestamp del dato.\n",
    "\n",
    "Las columnas de la 7 a 10 :'in' -(free cooling)-> 'evaporator' -(compresores)-> 'out'. Y  'ambient' sería la temperatura externa. Estas incluyen las medidas de las temperaturas en las enfriadoras (respectivamente de entrada, salida, en el evaporador y ambiente). Solo debería tener datos para node=\"1\" o \"2\" dependiendo de que enfriadora se trate. En cada celda se encuentra una serie temporal en formato diccionario en el que la key se corresponde con el timestamp del dato.\n",
    "\n",
    "Las columnas 11, 12: 'Compressor1', 'Compressor2' son equivalentes al punto \n",
    "anterior pero con los datos de presión en cada uno de los dos compresores de cada enfriadora. Solo debería tener datos para node=\"1\" o \"2\" dependiendo de que enfriadora se trate. En cada celda se encuentra una serie temporal en formato diccionario en el que la key se corresponde con el timestamp del dato.\n",
    "\n",
    "## Objetivos:\n",
    "Como series temporales usaremos (agrupando cada 30 minutos):\n",
    "### Suma del consumo de los nodos -  Originalmente en Wattios\n",
    "### Suma del consumo de las dos enfriadoras - KW (Power 13 enfriadora 1, Power 14 enfriadora 2)\n",
    "### Máximo de la presión de los 4 compresores - En Pascales (2 enfriadoras, 4 compresores, una lista con dos diccionarios en principio)\n",
    "### Número de compresores activos (compresores con presión mayor a 15 bars) \n",
    "### Cogeremos las temperaturas in, evaporator, out, ambient correspondientes a la enfriadora activa (la que tenga consumo mayor a 10KW) (referencia, agua caliente que volver del CPD es en torno a 18 grados)\n",
    "### Cogeremos la diferencia entre la temperatura ambient y el setpoint (se puede obtener como media de temperatura out) \n",
    "\n",
    "En total tenemos 9 series temporales (a determinar si interesa mantener por separado temperatura ambiente y la diferencia de temperatura entre ambiente y setpoint).\n",
    "\n",
    "Trataremos de hacer:\n",
    "- CU1: Predicción de la suma del consumo de las enfriadoras a 24h (será función de cuanto free cooling se pueda utilizar)\n",
    "- CU2: Predicción de la presión máxima a 24h\n",
    "\n",
    "Para el entrenamiento del CU1 podemos usar datos generales aunque serán más significativos los de invierno (sólo se puede usar free cooling aquellos momentos en que la temperatura ambiente es menor a la temperatura in, en verano esto solo es probable que ocurra durante la noche).\n",
    "\n",
    "Para el entrenamiento del CU2 son sólo relevantes los datos de los meses de verano.\n",
    "\n",
    "\n",
    "Para visualizar los datos se puede usar el siguiente dashboard:\n",
    "\n",
    "Dashboard:\n",
    "\n",
    "http://grafana.srv.cesga.es/d/000000016/dcim?orgId=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import os\n",
    "import copy\n",
    "import statsmodels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#Spark dependencies\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import StorageLevel, SparkConf\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler, PCA\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector, VectorUDT\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from pyspark.sql.types import TimestampType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "#Other configs\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "#Useful directory variables\n",
    "src_path = os.getcwd()\n",
    "root_path = os.path.dirname(src_path)\n",
    "data_path = root_path+\"/datasets\"\n",
    "visualization_path = root_path+\"/data_visualization\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer Paso: pasar de la tabla con el formato original conteniendo las series temporales como diccionarios en una celda (o una lista con dos diccionarios si hay dos series - Compresor 1 y 2 de Enfriadora 1 y lo mismo para enfriadora 2, a series temporales tabulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- node: string (nullable = true)\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- end_time: timestamp (nullable = true)\n",
      " |-- power: map (nullable = true)\n",
      " |    |-- key: timestamp\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      " |-- Power13: map (nullable = true)\n",
      " |    |-- key: timestamp\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      " |-- Power14: map (nullable = true)\n",
      " |    |-- key: timestamp\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      " |-- in: map (nullable = true)\n",
      " |    |-- key: timestamp\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      " |-- out: map (nullable = true)\n",
      " |    |-- key: timestamp\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      " |-- evaporator: map (nullable = true)\n",
      " |    |-- key: timestamp\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      " |-- ambient: map (nullable = true)\n",
      " |    |-- key: timestamp\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      " |-- Compressor1: map (nullable = true)\n",
      " |    |-- key: timestamp\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      " |-- Compressor2: map (nullable = true)\n",
      " |    |-- key: timestamp\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"output_final.parquet\") #Functional programming. Reading the raw data file with the Structured API\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"df\")\n",
    "node_list = spark.sql(\"SELECT node from df\").rdd.flatMap(lambda x: x).collect()#Getting the list with all the node names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos preparando la serie temporal para el consumo electrico de los nodos del cluster en Vatios. Para ello debemos hacer explode de todas las series temporales asociadas a nodos (todas las que estan en una fila cuyo valor en la columna node no sea \"1\", \"2\" o \"basement\". Despues las agruparemos (con media) cada 30 minutos y por ultima realizaremos la suma para tener el total de consumo medio en Vatios cada 30 minutos. Es importante notar que no se puede sumar primero y luego agrupar ya que cada una de las series temporales tiene medidas para un valor de tiempo distinto (difieren en el orden de los segundos) tal y como se ve para c6601 y c7102 en el notebook eDA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for node in node_list[:-3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+------+-----+\n",
      "|               time|              start|                end| power|count|\n",
      "+-------------------+-------------------+-------------------+------+-----+\n",
      "|2018-01-01 00:00:44|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:01:57|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:03:09|2018-01-01 00:00:00|2018-01-01 00:30:00|[72.0]|    1|\n",
      "|2018-01-01 00:04:21|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:05:33|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:06:45|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:07:57|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:09:08|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:10:20|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:11:33|2018-01-01 00:00:00|2018-01-01 00:30:00|[90.0]|    1|\n",
      "|2018-01-01 00:12:45|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:13:57|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:15:09|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:16:20|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:17:32|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:18:44|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:19:57|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:21:09|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:22:20|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:23:31|2018-01-01 00:00:00|2018-01-01 00:30:00|[72.0]|    1|\n",
      "|2018-01-01 00:24:43|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:25:55|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:27:07|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:28:19|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:29:31|2018-01-01 00:00:00|2018-01-01 00:30:00|[54.0]|    1|\n",
      "|2018-01-01 00:30:43|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:31:59|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:33:23|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:34:46|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:36:12|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:37:30|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:38:53|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:40:11|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:41:31|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:42:49|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:44:08|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:45:24|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:46:39|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:47:53|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "|2018-01-01 00:49:10|2018-01-01 00:30:00|2018-01-01 01:00:00|[54.0]|    1|\n",
      "+-------------------+-------------------+-------------------+------+-----+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_dates = '''\n",
    "                SELECT \n",
    "                    start_time,\n",
    "                    end_time\n",
    "                FROM df\n",
    "\n",
    "            '''.format(node_list[0],node_list[0])\n",
    "sql_query_node_consumption = '''\n",
    "                SELECT \n",
    "                    EXPLODE(power) as (time, electric_consumption_node_{}) \n",
    "                FROM df\n",
    "                WHERE \n",
    "                    node LIKE \"{}\"\n",
    "            '''.format(node_list[0],node_list[0])\n",
    "node_consumption = spark.sql(sql_query_node_consumption)\n",
    "dates = spark.sql(sql_query_dates)\n",
    "node_consumption = node_consumption.withColumn(\"time\", F.to_timestamp(node_consumption.time ,\"yyyy-MM-dd HH:MM:SS\"))\n",
    "sub = node_consumption.groupBy(\"time\", F.window(\"time\", \"30 minutes\")).agg(F.expr(\"collect_list(electric_consumption_node_c6601)\").alias(\"power\"), F.expr(\"count('time')\").alias(\"count\"),)\n",
    "sub=sub.select(\"time\", \"window.*\", \"power\", \"count\").sort(F.asc(\"time\"))\n",
    "sub.show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDEA ORIGINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_consumption_pandas=node_consumption.limit(1000).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>electric_consumption_node_c6601</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:44</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:01:57</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:03:09</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:04:21</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:05:33</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01 00:06:45</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-01 00:07:57</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-01 00:09:08</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-01 00:10:20</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-01 00:11:33</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-01 00:12:45</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-01 00:13:57</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-01 00:15:09</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-01 00:16:20</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-01 00:17:32</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-01 00:18:44</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-01 00:19:57</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-01 00:21:09</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-01 00:22:20</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-01 00:23:31</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-01 00:24:43</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-01 00:25:55</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-01-01 00:27:07</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-01-01 00:28:19</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-01-01 00:29:31</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-01-01 00:30:43</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-01-01 00:31:59</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-01-01 00:33:23</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-01-01 00:34:46</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-01-01 00:36:12</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  electric_consumption_node_c6601\n",
       "0  2018-01-01 00:00:44                            54.00\n",
       "1  2018-01-01 00:01:57                            54.00\n",
       "2  2018-01-01 00:03:09                            72.00\n",
       "3  2018-01-01 00:04:21                            54.00\n",
       "4  2018-01-01 00:05:33                            54.00\n",
       "5  2018-01-01 00:06:45                            54.00\n",
       "6  2018-01-01 00:07:57                            54.00\n",
       "7  2018-01-01 00:09:08                            54.00\n",
       "8  2018-01-01 00:10:20                            54.00\n",
       "9  2018-01-01 00:11:33                            90.00\n",
       "10 2018-01-01 00:12:45                            54.00\n",
       "11 2018-01-01 00:13:57                            54.00\n",
       "12 2018-01-01 00:15:09                            54.00\n",
       "13 2018-01-01 00:16:20                            54.00\n",
       "14 2018-01-01 00:17:32                            54.00\n",
       "15 2018-01-01 00:18:44                            54.00\n",
       "16 2018-01-01 00:19:57                            54.00\n",
       "17 2018-01-01 00:21:09                            54.00\n",
       "18 2018-01-01 00:22:20                            54.00\n",
       "19 2018-01-01 00:23:31                            72.00\n",
       "20 2018-01-01 00:24:43                            54.00\n",
       "21 2018-01-01 00:25:55                            54.00\n",
       "22 2018-01-01 00:27:07                            54.00\n",
       "23 2018-01-01 00:28:19                            54.00\n",
       "24 2018-01-01 00:29:31                            54.00\n",
       "25 2018-01-01 00:30:43                            54.00\n",
       "26 2018-01-01 00:31:59                            54.00\n",
       "27 2018-01-01 00:33:23                            54.00\n",
       "28 2018-01-01 00:34:46                            54.00\n",
       "29 2018-01-01 00:36:12                            54.00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_consumption_pandas.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>window</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 12:33:04</td>\n",
       "      <td>(2018-01-01 12:30:00, 2018-01-01 13:00:00)</td>\n",
       "      <td>108.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 16:33:32</td>\n",
       "      <td>(2018-01-01 16:30:00, 2018-01-01 17:00:00)</td>\n",
       "      <td>108.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 19:55:46</td>\n",
       "      <td>(2018-01-01 19:30:00, 2018-01-01 20:00:00)</td>\n",
       "      <td>108.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02 02:18:10</td>\n",
       "      <td>(2018-01-02 02:00:00, 2018-01-02 02:30:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-02 06:36:48</td>\n",
       "      <td>(2018-01-02 06:30:00, 2018-01-02 07:00:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-02 06:53:33</td>\n",
       "      <td>(2018-01-02 06:30:00, 2018-01-02 07:00:00)</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-02 07:19:53</td>\n",
       "      <td>(2018-01-02 07:00:00, 2018-01-02 07:30:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-02 09:28:53</td>\n",
       "      <td>(2018-01-02 09:00:00, 2018-01-02 09:30:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-02 13:27:24</td>\n",
       "      <td>(2018-01-02 13:00:00, 2018-01-02 13:30:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-03 00:18:36</td>\n",
       "      <td>(2018-01-03 00:00:00, 2018-01-03 00:30:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-03 06:16:58</td>\n",
       "      <td>(2018-01-03 06:00:00, 2018-01-03 06:30:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-03 16:32:15</td>\n",
       "      <td>(2018-01-03 16:30:00, 2018-01-03 17:00:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-04 21:22:35</td>\n",
       "      <td>(2018-01-04 21:00:00, 2018-01-04 21:30:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-05 13:32:04</td>\n",
       "      <td>(2018-01-05 13:30:00, 2018-01-05 14:00:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-05 22:09:46</td>\n",
       "      <td>(2018-01-05 22:00:00, 2018-01-05 22:30:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-06 02:10:07</td>\n",
       "      <td>(2018-01-06 02:00:00, 2018-01-06 02:30:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-06 10:28:59</td>\n",
       "      <td>(2018-01-06 10:00:00, 2018-01-06 10:30:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-06 11:56:12</td>\n",
       "      <td>(2018-01-06 11:30:00, 2018-01-06 12:00:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-06 13:06:52</td>\n",
       "      <td>(2018-01-06 13:00:00, 2018-01-06 13:30:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-06 19:29:10</td>\n",
       "      <td>(2018-01-06 19:00:00, 2018-01-06 19:30:00)</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time                                      window  power\n",
       "0  2018-01-01 12:33:04  (2018-01-01 12:30:00, 2018-01-01 13:00:00) 108.00\n",
       "1  2018-01-01 16:33:32  (2018-01-01 16:30:00, 2018-01-01 17:00:00) 108.00\n",
       "2  2018-01-01 19:55:46  (2018-01-01 19:30:00, 2018-01-01 20:00:00) 108.00\n",
       "3  2018-01-02 02:18:10  (2018-01-02 02:00:00, 2018-01-02 02:30:00)  54.00\n",
       "4  2018-01-02 06:36:48  (2018-01-02 06:30:00, 2018-01-02 07:00:00)  54.00\n",
       "5  2018-01-02 06:53:33  (2018-01-02 06:30:00, 2018-01-02 07:00:00)  90.00\n",
       "6  2018-01-02 07:19:53  (2018-01-02 07:00:00, 2018-01-02 07:30:00)  54.00\n",
       "7  2018-01-02 09:28:53  (2018-01-02 09:00:00, 2018-01-02 09:30:00)  54.00\n",
       "8  2018-01-02 13:27:24  (2018-01-02 13:00:00, 2018-01-02 13:30:00)  54.00\n",
       "9  2018-01-03 00:18:36  (2018-01-03 00:00:00, 2018-01-03 00:30:00)  54.00\n",
       "10 2018-01-03 06:16:58  (2018-01-03 06:00:00, 2018-01-03 06:30:00)  54.00\n",
       "11 2018-01-03 16:32:15  (2018-01-03 16:30:00, 2018-01-03 17:00:00)  54.00\n",
       "12 2018-01-04 21:22:35  (2018-01-04 21:00:00, 2018-01-04 21:30:00)  54.00\n",
       "13 2018-01-05 13:32:04  (2018-01-05 13:30:00, 2018-01-05 14:00:00)  54.00\n",
       "14 2018-01-05 22:09:46  (2018-01-05 22:00:00, 2018-01-05 22:30:00)  54.00\n",
       "15 2018-01-06 02:10:07  (2018-01-06 02:00:00, 2018-01-06 02:30:00)  54.00\n",
       "16 2018-01-06 10:28:59  (2018-01-06 10:00:00, 2018-01-06 10:30:00)  54.00\n",
       "17 2018-01-06 11:56:12  (2018-01-06 11:30:00, 2018-01-06 12:00:00)  54.00\n",
       "18 2018-01-06 13:06:52  (2018-01-06 13:00:00, 2018-01-06 13:30:00)  54.00\n",
       "19 2018-01-06 19:29:10  (2018-01-06 19:00:00, 2018-01-06 19:30:00)  54.00"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "fecha_fija = \"2018-01-01 00:00:00\"\n",
    "start_time = datetime.strptime(fecha_fija,\"%Y-%m-%d %H:%M:%S\")\n",
    "minutes_since_1970_to_start_time = int(time.mktime(start_time.timetuple())/60)#Passing the total seconds to minutes dividing by 60\n",
    "offset_minutes = minutes_since_1970_to_start_time % 30 #offset minutes\n",
    "window_30_mins = F.window(\"time\", \"30 minutes\", startTime = \"{} minutes\".format(offset_minutes))\n",
    "pandas=node_consumption.groupBy(\"time\", window_30_mins).agg(F.mean(\"electric_consumption_node_c6601\").alias(\"power\")).limit(20).toPandas()\n",
    "pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 1, 1, 0, 0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fecha_fija = \"2018-01-01 00:00:00\"\n",
    "start_time = datetime.strptime(fecha_fija,\"%Y-%m-%d %H:%M:%S\")\n",
    "start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BORRADOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|         start_time|           end_time|\n",
      "+-------------------+-------------------+\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "|2018-01-01 01:00:00|2021-06-01 02:00:00|\n",
      "+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dates.show()#All the nodes has the same starting and ending date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
