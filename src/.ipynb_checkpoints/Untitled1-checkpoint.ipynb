{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import statsmodels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Spark dependencies\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import StorageLevel, SparkConf\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler, PCA\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector, VectorUDT\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.types import TimestampType\n",
    "from pyspark.sql.functions import col, expr, udf, sequence\n",
    "\n",
    "# Other configs\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "# Useful directory variables\n",
    "src_path = os.getcwd()\n",
    "root_path = os.path.dirname(src_path)\n",
    "data_path = root_path + \"/datasets\"\n",
    "visualization_path = root_path + \"/data_visualization\"\n",
    "\n",
    "# Start counting time\n",
    "start_t = time.time()\n",
    "# Reading the original file\n",
    "df = spark.read.parquet(\n",
    "    \"output_final.parquet\"\n",
    ")  # Functional programming. Reading the raw data file with the Structured API\n",
    "# df.printSchema()\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "# Generating a dataFrame with the times (every 30 minutes from start_timestamp to end_timestamp)\n",
    "dates = pd.date_range(\n",
    "    start=datetime(2018, 1, 1, 0, 0, 0),\n",
    "    end=datetime(2021, 6, 30, 0, 0, 0),\n",
    "    freq=\"30min\",\n",
    ")\n",
    "datetimes = [date.to_pydatetime() for date in dates]\n",
    "time_df = (\n",
    "    spark.createDataFrame(datetimes, TimestampType())\n",
    "    .withColumnRenamed(\"value\", \"time\")\n",
    "    .sort(F.asc(\"time\"))\n",
    ")\n",
    "\n",
    "# Obtaning each consumption node in a list\n",
    "node_list = (\n",
    "    spark.sql(\"SELECT node from df\").rdd.flatMap(lambda x: x).collect()\n",
    ")  # Getting the list with all the node names\n",
    "\n",
    "\n",
    "# Obtaning each consumption node:\n",
    "# We are having two time related Spark Dataframes that originally prior to iterate will be identical\n",
    "# time_df: will remain unchanged during the whole execution, just a reference to ensure all the times are met and if not a null is given for the corresponding electrical consumption column\n",
    "# consumption_df: this will suffer a left join at the end of each iteration and will be the container for all the consumption columns\n",
    "consumption_df = spark.createDataFrame(time_df.rdd, time_df.schema)\n",
    "consumption_df = consumption_df.withColumn(\"total_average_power_consumption_W\", lit(0))\n",
    "# for node in node_list[0:1]:  # All the consumption related cluster nodes\n",
    "sql_query_node_consumption =  \"\"\"\n",
    "                SELECT \n",
    "                    EXPLODE(ambient) as (time, chiller_1_power_consumption) \n",
    "                FROM df\n",
    "                WHERE \n",
    "                    node = \"2\"\n",
    "            \"\"\"\n",
    "node_consumption = spark.sql(sql_query_node_consumption)\n",
    "node_consumption = node_consumption.withColumn(\n",
    "    \"time\", F.to_timestamp(node_consumption.time, \"yyyy-MM-dd HH:MM:SS\")\n",
    ")\n",
    "#     node_consumption = node_consumption.groupBy(\n",
    "#         \"time\", F.window(\"time\", \"30 minutes\")\n",
    "#     ).agg(\n",
    "#         avg(\"node_{}_power_consumption\".format(node)).alias(\n",
    "#             \"node_{}_power_consumption\".format(node)\n",
    "#         ),\n",
    "#     )\n",
    "#     node_consumption = node_consumption.select(\n",
    "#         \"time\", \"window.*\", \"node_{}_power_consumption\".format(node)\n",
    "#     ).sort(F.asc(\"time\"))\n",
    "#     node_consumption = node_consumption.select(\n",
    "#         col(\"end\").alias(\"time\"), col(\"node_{}_power_consumption\".format(node))\n",
    "#     )\n",
    "#     node_consumption = node_consumption.groupBy(\"time\").agg(\n",
    "#         avg(\"node_{}_power_consumption\".format(node)).alias(\n",
    "#             \"node_{}_average_power_consumption\".format(node)\n",
    "#         )\n",
    "#     )\n",
    "#     node_consumption = node_consumption.select(\n",
    "#         \"time\", \"node_{}_average_power_consumption\".format(node)\n",
    "#     ).sort(F.asc(\"time\"))\n",
    "#     consumption_df = consumption_df.join(node_consumption, [\"time\"], how=\"left\").sort(\n",
    "#         F.asc(\"time\")\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_consumption.where(node_consumption.time == datetime(2018, 3, 25, 0, 0, 0))\n",
    "a=node_consumption.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>node_c6601_power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, node_c6601_power_consumption]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a.duplicated()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
